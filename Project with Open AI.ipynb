{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d35625",
   "metadata": {},
   "source": [
    "# Project With OPEN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e2cb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\karthick\\anaconda3\\lib\\site-packages (0.27.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from aiohttp->openai) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\karthick\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->openai) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2f882",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33bddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key  = 'Use Your API Key'     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23e7d3",
   "metadata": {},
   "source": [
    "## helper function\n",
    "\n",
    "- using OpenAI's gpt-3.5-turbo model and the chat completions endpoint.\n",
    "\n",
    "- This helper function will make it easier to use prompts and look at the generated outputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98380e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a858f6",
   "metadata": {},
   "source": [
    "Prompting Principles\n",
    "\n",
    "    Principle 1: Write clear and specific instructions\n",
    "    Principle 2: Give the model time to “think”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea43987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I cannot develop code. However, I can provide you with a sample code for Naive Bayes Algorithm using the internal dataset in the sklearn library and calculating error metrics such as accuracy score, confusion matrix, and overall report.\n",
      "\n",
      "Here is the sample code:\n",
      "\n",
      "```\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Load the iris dataset\n",
      "iris = load_iris()\n",
      "\n",
      "# Split the dataset into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
      "\n",
      "# Create a Gaussian Naive Bayes model\n",
      "gnb = GaussianNB()\n",
      "\n",
      "# Train the model using the training data\n",
      "gnb.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions on the testing data\n",
      "y_pred = gnb.predict(X_test)\n",
      "\n",
      "# Calculate the accuracy score\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "\n",
      "# Calculate the confusion matrix\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "\n",
      "# Calculate the classification report\n",
      "cr = classification_report(y_test, y_pred)\n",
      "\n",
      "# Print the results\n",
      "print(\"Accuracy Score: \", accuracy)\n",
      "print(\"Confusion Matrix: \\n\", cm)\n",
      "print(\"Classification Report: \\n\", cr)\n",
      "```\n",
      "\n",
      "In this code, we first load the iris dataset from the sklearn library and split it into training and testing sets. We then create a Gaussian Naive Bayes model and train it using the training data. We make predictions on the testing data and calculate the accuracy score, confusion matrix, and classification report. Finally, we print the results.\n",
      "\n",
      "Note that this is just a sample code, and you may need to modify it based on your specific use case and dataset.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "assume you as Machine Learnig Devloper , Develop python code for NaiveBase Algorithm Model with internal data set \n",
    "in sklearn library and also claculate error metrics as accuracy score, confusion matrix, overall report\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9500ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Movie_ID\": 1,\n",
      "    \"title\": \"The Last Voyage\",\n",
      "    \"Director\": \"Ava Lee Scott\",\n",
      "    \"genre\": \"Sci-Fi\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"Movie_ID\": 2,\n",
      "    \"title\": \"The Lost City\",\n",
      "    \"Director\": \"Maxwell Stone\",\n",
      "    \"genre\": \"Adventure\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"Movie_ID\": 3,\n",
      "    \"title\": \"The Darkening\",\n",
      "    \"Director\": \"Evelyn Blackwood\",\n",
      "    \"genre\": \"Horror\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up movie titles along \\ \n",
    "with their director and genres. \n",
    "Provide them in python dict format with the following keys: \n",
    "Movie_ID, title, Director, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7004464",
   "metadata": {},
   "outputs": [],
   "source": [
    "code='''\n",
    "```\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using the training data\n",
    "gnb.fit(X_train, X_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy Score: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(\"Classification Report: \\n\", cr)\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e96ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The second argument in the gnb.fit() method should be y_train instead of X_train.\n",
      "Corrected code:\n",
      "```\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Load the iris dataset\n",
      "iris = load_iris()\n",
      "\n",
      "# Split the dataset into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
      "\n",
      "# Create a Gaussian Naive Bayes model\n",
      "gnb = GaussianNB()\n",
      "\n",
      "# Train the model using the training data\n",
      "gnb.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions on the testing data\n",
      "y_pred = gnb.predict(X_test)\n",
      "\n",
      "# Calculate the accuracy score\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "\n",
      "# Calculate the confusion matrix\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "\n",
      "# Calculate the classification report\n",
      "cr = classification_report(y_test, y_pred)\n",
      "\n",
      "# Print the results\n",
      "print(\"Accuracy Score: \", accuracy)\n",
      "print(\"Confusion Matrix:\\n\", cm)\n",
      "print(\"Classification Report:\\n\", cr)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "find the Error in the given code:{code}\n",
    "and corect it, say what is the error in seperate line\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdc5e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To deploy the model in the given code, follow these steps:\n",
      "\n",
      "1. Save the trained model using joblib or pickle.\n",
      "2. Load the saved model in a new script or application.\n",
      "3. Use the loaded model to make predictions on new data.\n",
      "\n",
      "Here's an example of how to save and load the trained model using joblib:\n",
      "\n",
      "```\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "# Save the trained model\n",
      "joblib.dump(gnb, 'gnb_model.pkl')\n",
      "\n",
      "# Load the saved model\n",
      "loaded_model = joblib.load('gnb_model.pkl')\n",
      "\n",
      "# Use the loaded model to make predictions on new data\n",
      "new_data = [[5.1, 3.5, 1.4, 0.2], [6.2, 2.9, 4.3, 1.3], [7.3, 2.9, 6.3, 1.8]]\n",
      "predictions = loaded_model.predict(new_data)\n",
      "\n",
      "# Print the predictions\n",
      "print(predictions)\n",
      "```\n",
      "\n",
      "In this example, we save the trained model using joblib.dump() and load it using joblib.load(). We then use the loaded model to make predictions on new data and print the results.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "deploy the model in the  given code:{code}\n",
    "and give the step to follow\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e6e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b6d8ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir,\n",
      "\n",
      "I am writing to request a leave of absence for two days due to my brother's wedding. \n",
      "\n",
      "Thank you for your understanding.\n",
      "\n",
      "Sincerely, [Your Name]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a professional letter: \n",
    "'sir,i need leave for two days  bcz of my brother marage.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424bd1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sir, I need leave for two days because of my brother's marriage.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "spell check and correct it : \n",
    "'sir,i need leave for two days  bcz of my brother marage.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76aae91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell check and correct: \"Sir, I need leave for two days because of my brother's marriage.\"\n",
      "\n",
      "Translation into Hindi: \"सर, मेरे भाई की शादी के कारण मुझे दो दिन की छुट्टी चाहिए।\"\n",
      "\n",
      "Translation into Tamil: \"சார், எனக்கு எருமை தம்பி திருமணம் காரணமாக இரண்டு நாட்கள் அவசியம்.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "spell check and correct it Translate into hindi and Tamil: \n",
    "'sir,i need leave for two days  bcz of my brother marage.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b75c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59c81762",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "971da990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government survey, job satisfaction, NASA, Social Security Administration, employee concerns\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41e2a4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['government survey',\n",
       " ' job satisfaction',\n",
       " ' NASA',\n",
       " ' Social Security Administration',\n",
       " ' employee concerns']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164dd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994aa84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dca899c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e339eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcfdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98dc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
